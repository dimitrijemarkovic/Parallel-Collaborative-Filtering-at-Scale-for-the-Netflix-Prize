{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29babe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RBM with LR=0.5, Hidden Layers=100, Weight Decay=0.0001\n",
      "Epoch 0: Loss=0.2633781433105469\n",
      "Epoch 10: Loss=0.3737131357192993\n",
      "Epoch 20: Loss=0.12262508273124695\n",
      "Epoch 30: Loss=0.10167749226093292\n",
      "Epoch 40: Loss=0.08068560063838959\n",
      "Epoch 50: Loss=0.08107228577136993\n",
      "Epoch 60: Loss=0.08172430843114853\n",
      "Epoch 70: Loss=0.07595827430486679\n",
      "Epoch 80: Loss=0.07606039196252823\n",
      "Epoch 90: Loss=0.07731418311595917\n",
      "LR=0.5, Hidden Layers=100, Weight Decay=0.0001 => RMSE: 0.7324761748313904, MAE: 0.5883461236953735\n",
      "Training RBM with LR=0.5, Hidden Layers=100, Weight Decay=0.001\n",
      "Epoch 0: Loss=0.2627525329589844\n",
      "Epoch 10: Loss=0.19310899078845978\n",
      "Epoch 20: Loss=0.15837927162647247\n",
      "Epoch 30: Loss=0.0867263525724411\n",
      "Epoch 40: Loss=0.0840994268655777\n",
      "Epoch 50: Loss=0.08360791206359863\n",
      "Epoch 60: Loss=0.08656520396471024\n",
      "Epoch 70: Loss=0.08499704301357269\n",
      "Epoch 80: Loss=0.0967404767870903\n",
      "Epoch 90: Loss=0.09367476403713226\n",
      "LR=0.5, Hidden Layers=100, Weight Decay=0.001 => RMSE: 0.6598947048187256, MAE: 0.517475426197052\n",
      "Training RBM with LR=0.5, Hidden Layers=200, Weight Decay=0.0001\n",
      "Epoch 0: Loss=0.2697924077510834\n",
      "Epoch 10: Loss=0.803056001663208\n",
      "Epoch 20: Loss=0.1796981543302536\n",
      "Epoch 30: Loss=0.13653726875782013\n",
      "Epoch 40: Loss=0.10179160535335541\n",
      "Epoch 50: Loss=0.09235545247793198\n",
      "Epoch 60: Loss=0.08839654177427292\n",
      "Epoch 70: Loss=0.09784743934869766\n",
      "Epoch 80: Loss=0.08605599403381348\n",
      "Epoch 90: Loss=0.09751354157924652\n",
      "LR=0.5, Hidden Layers=200, Weight Decay=0.0001 => RMSE: 0.7536210417747498, MAE: 0.6103975176811218\n",
      "Training RBM with LR=0.5, Hidden Layers=200, Weight Decay=0.001\n",
      "Epoch 0: Loss=0.27028632164001465\n",
      "Epoch 10: Loss=0.15762875974178314\n",
      "Epoch 20: Loss=0.2389707714319229\n",
      "Epoch 30: Loss=0.11314332485198975\n",
      "Epoch 40: Loss=0.11272300779819489\n",
      "Epoch 50: Loss=0.09260548651218414\n",
      "Epoch 60: Loss=0.09328921139240265\n",
      "Epoch 70: Loss=0.08941908180713654\n",
      "Epoch 80: Loss=0.0938669964671135\n",
      "Epoch 90: Loss=0.09180206060409546\n",
      "LR=0.5, Hidden Layers=200, Weight Decay=0.001 => RMSE: 0.6607605814933777, MAE: 0.5147567391395569\n",
      "Training RBM with LR=0.5, Hidden Layers=300, Weight Decay=0.0001\n",
      "Epoch 0: Loss=0.28192368149757385\n",
      "Epoch 10: Loss=0.6139033436775208\n",
      "Epoch 20: Loss=0.17978441715240479\n",
      "Epoch 30: Loss=0.14025495946407318\n",
      "Epoch 40: Loss=0.13121940195560455\n",
      "Epoch 50: Loss=0.1021573543548584\n",
      "Epoch 60: Loss=0.13749487698078156\n",
      "Epoch 70: Loss=0.1045856699347496\n",
      "Epoch 80: Loss=0.09665107727050781\n",
      "Epoch 90: Loss=0.09423638135194778\n",
      "LR=0.5, Hidden Layers=300, Weight Decay=0.0001 => RMSE: 0.7217996120452881, MAE: 0.587426483631134\n",
      "Training RBM with LR=0.5, Hidden Layers=300, Weight Decay=0.001\n",
      "Epoch 0: Loss=0.273671954870224\n",
      "Epoch 10: Loss=0.11709639430046082\n",
      "Epoch 20: Loss=0.21761126816272736\n",
      "Epoch 30: Loss=0.11981590837240219\n",
      "Epoch 40: Loss=0.09076617658138275\n",
      "Epoch 50: Loss=0.09753481298685074\n",
      "Epoch 60: Loss=0.09251593053340912\n",
      "Epoch 70: Loss=0.09826737642288208\n",
      "Epoch 80: Loss=0.11992093175649643\n",
      "Epoch 90: Loss=0.11859430372714996\n",
      "LR=0.5, Hidden Layers=300, Weight Decay=0.001 => RMSE: 0.6494985222816467, MAE: 0.5193375945091248\n",
      "Training RBM with LR=0.005, Hidden Layers=100, Weight Decay=0.0001\n",
      "Epoch 0: Loss=0.2644980549812317\n",
      "Epoch 10: Loss=0.14827045798301697\n",
      "Epoch 20: Loss=0.11414133012294769\n",
      "Epoch 30: Loss=0.09907309710979462\n",
      "Epoch 40: Loss=0.08881017565727234\n",
      "Epoch 50: Loss=0.08154934644699097\n",
      "Epoch 60: Loss=0.07699088752269745\n",
      "Epoch 70: Loss=0.0731973871588707\n",
      "Epoch 80: Loss=0.07113375514745712\n",
      "Epoch 90: Loss=0.0695870891213417\n",
      "LR=0.005, Hidden Layers=100, Weight Decay=0.0001 => RMSE: 0.660976231098175, MAE: 0.516863226890564\n",
      "Training RBM with LR=0.005, Hidden Layers=100, Weight Decay=0.001\n",
      "Epoch 0: Loss=0.266115665435791\n",
      "Epoch 10: Loss=0.21878935396671295\n",
      "Epoch 20: Loss=0.15973784029483795\n",
      "Epoch 30: Loss=0.13244900107383728\n",
      "Epoch 40: Loss=0.118071049451828\n",
      "Epoch 50: Loss=0.10989195108413696\n",
      "Epoch 60: Loss=0.10784562677145004\n",
      "Epoch 70: Loss=0.10488355159759521\n",
      "Epoch 80: Loss=0.10181307792663574\n",
      "Epoch 90: Loss=0.09937166422605515\n",
      "LR=0.005, Hidden Layers=100, Weight Decay=0.001 => RMSE: 0.6288995742797852, MAE: 0.4929995834827423\n",
      "Training RBM with LR=0.005, Hidden Layers=200, Weight Decay=0.0001\n",
      "Epoch 0: Loss=0.27180007100105286\n",
      "Epoch 10: Loss=0.1200520470738411\n",
      "Epoch 20: Loss=0.09634535759687424\n",
      "Epoch 30: Loss=0.0847998857498169\n",
      "Epoch 40: Loss=0.07524324208498001\n",
      "Epoch 50: Loss=0.06895196437835693\n",
      "Epoch 60: Loss=0.06521722674369812\n",
      "Epoch 70: Loss=0.0636495053768158\n",
      "Epoch 80: Loss=0.063118115067482\n",
      "Epoch 90: Loss=0.06280063092708588\n",
      "LR=0.005, Hidden Layers=200, Weight Decay=0.0001 => RMSE: 0.6739925146102905, MAE: 0.5281332731246948\n",
      "Training RBM with LR=0.005, Hidden Layers=200, Weight Decay=0.001\n",
      "Epoch 0: Loss=0.2693300247192383\n",
      "Epoch 10: Loss=0.19867803156375885\n",
      "Epoch 20: Loss=0.14241084456443787\n",
      "Epoch 30: Loss=0.1218942180275917\n",
      "Epoch 40: Loss=0.10789903253316879\n",
      "Epoch 50: Loss=0.10324189811944962\n",
      "Epoch 60: Loss=0.0997641384601593\n",
      "Epoch 70: Loss=0.09621141850948334\n",
      "Epoch 80: Loss=0.09328070282936096\n",
      "Epoch 90: Loss=0.09115302562713623\n",
      "LR=0.005, Hidden Layers=200, Weight Decay=0.001 => RMSE: 0.6424996256828308, MAE: 0.5012199878692627\n",
      "Training RBM with LR=0.005, Hidden Layers=300, Weight Decay=0.0001\n",
      "Epoch 0: Loss=0.273204505443573\n",
      "Epoch 10: Loss=0.10481204092502594\n",
      "Epoch 20: Loss=0.0859583243727684\n",
      "Epoch 30: Loss=0.07620365172624588\n",
      "Epoch 40: Loss=0.06870878487825394\n",
      "Epoch 50: Loss=0.06370250135660172\n",
      "Epoch 60: Loss=0.06137072294950485\n",
      "Epoch 70: Loss=0.06079644709825516\n",
      "Epoch 80: Loss=0.060589343309402466\n",
      "Epoch 90: Loss=0.06038001924753189\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "df_pivot = pd.read_csv('pivot_table.csv', index_col=0)\n",
    "df_melt = df_pivot.stack().reset_index().rename(columns={'level_1': 'Movie_Id', 0: 'Rating'})\n",
    "\n",
    "\n",
    "user_movie_matrix = df_pivot.values\n",
    "n_users, n_movies = user_movie_matrix.shape\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "user_movie_matrix_normalized = scaler.fit_transform(user_movie_matrix)\n",
    "\n",
    "\n",
    "def flatten_matrix(matrix):\n",
    "    return [(i, j, matrix[i, j]) for i in range(matrix.shape[0]) for j in range(matrix.shape[1]) if matrix[i, j] > 0]\n",
    "\n",
    "ratings_flat = flatten_matrix(user_movie_matrix_normalized)\n",
    "train_data, test_data = train_test_split(ratings_flat, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def to_tensor(data, n_users, n_movies):\n",
    "    matrix = torch.zeros(n_users, n_movies)\n",
    "    for i, j, r in data:\n",
    "        matrix[int(i), int(j)] = r\n",
    "    return matrix\n",
    "\n",
    "train_tensor = to_tensor(train_data, n_users, n_movies)\n",
    "test_tensor = to_tensor(test_data, n_users, n_movies)\n",
    "\n",
    "\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_visible, n_hidden):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_visible, n_hidden) * 0.1)\n",
    "        self.b = nn.Parameter(torch.zeros(n_visible))\n",
    "        self.c = nn.Parameter(torch.zeros(n_hidden))\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, v):\n",
    "        h_prob = torch.relu(torch.matmul(v, self.W) + self.c)  \n",
    "        h_prob = self.dropout(h_prob)\n",
    "        v_recon = torch.sigmoid(torch.matmul(h_prob, self.W.t()) + self.b)\n",
    "        return v_recon\n",
    "\n",
    "\n",
    "learning_rates = [0.5,0.005, 0.01]\n",
    "hidden_layers = [100, 200, 300]\n",
    "weight_decays = [0.0001, 0.001]\n",
    "results = []\n",
    "\n",
    "n\n",
    "for lr in learning_rates:\n",
    "    for n_hidden in hidden_layers:\n",
    "        for wd in weight_decays:\n",
    "            print(f'Training RBM with LR={lr}, Hidden Layers={n_hidden}, Weight Decay={wd}')\n",
    "            \n",
    "            rbm = RBM(n_visible=n_movies, n_hidden=n_hidden)\n",
    "            optimizer = optim.Adam(rbm.parameters(), lr=lr, weight_decay=wd)\n",
    "            \n",
    "            \n",
    "            def train_rbm(model, train_data, optimizer, epochs=100):  \n",
    "                for epoch in range(epochs):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    recon = model(train_data)\n",
    "                    loss = nn.MSELoss()(recon, train_data)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    if epoch % 10 == 0:\n",
    "                        print(f'Epoch {epoch}: Loss={loss.item()}')\n",
    "            \n",
    "            train_rbm(rbm, train_tensor, optimizer)\n",
    "            \n",
    "            \n",
    "            def evaluate_rbm(model, test_data):\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    pred = model(test_tensor)\n",
    "                    pred = pred.numpy()\n",
    "                    test_matrix = test_tensor.numpy()\n",
    "\n",
    "                    \n",
    "                    test_flat = [(i, j, test_matrix[i, j]) for i in range(test_matrix.shape[0]) for j in range(test_matrix.shape[1]) if test_matrix[i, j] > 0]\n",
    "                    pred_flat = [(i, j, pred[i, j]) for i in range(pred.shape[0]) for j in range(pred.shape[1]) if test_matrix[i, j] > 0]\n",
    "\n",
    "                    \n",
    "                    test_ratings = np.array([r for _, _, r in test_flat])\n",
    "                    pred_ratings = np.array([r for _, _, r in pred_flat])\n",
    "\n",
    "                    rmse = np.sqrt(mean_squared_error(test_ratings, pred_ratings))\n",
    "                    mae = mean_absolute_error(test_ratings, pred_ratings)\n",
    "                    return rmse, mae\n",
    "\n",
    "            rmse, mae = evaluate_rbm(rbm, test_tensor)\n",
    "            results.append((lr, n_hidden, wd, rmse, mae))\n",
    "            print(f'LR={lr}, Hidden Layers={n_hidden}, Weight Decay={wd} => RMSE: {rmse}, MAE: {mae}')\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Learning Rate', 'Hidden Layers', 'Weight Decay', 'RMSE', 'MAE'])\n",
    "print(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04a46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
